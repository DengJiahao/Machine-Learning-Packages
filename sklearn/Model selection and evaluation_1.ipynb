{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and evaluation 1\n",
    "___\n",
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overfitting, we usually use [cross-validation][1].  \n",
    "Typically used cross-validation methods include:\n",
    "\n",
    "- **Exhaustive cross-validation**  \n",
    "\n",
    "    ```\n",
    "Exhaustive cross-validation methods are cross-validation methods which learn and test on all possible ways to divide the original sample into a training and a validation set.\n",
    "    ```\n",
    "\n",
    "    - **Leave-p-out cross-validation**  \n",
    "    From all the data points, select $p$ data points to test and use the other data to train the model. Repeat the process to include all the possible combination.\n",
    "    \n",
    "    - **Leave-one-out cross-validation**  \n",
    "    The $p = 1$ scenario of *Leave-p-out cross-validation*.\n",
    "- **Non-exhaustive cross-validation**  \n",
    "\n",
    "    ```\n",
    "Non-exhaustive cross validation methods do not compute all ways of splitting the original sample. Those methods are approximations of leave-p-out cross-validation.\n",
    "    ```\n",
    "    - **k-fold cross-validation**  \n",
    "       ![](K-fold_cross_validation_EN.jpg)\n",
    "    - **Holdout method**  \n",
    "    Very simple method. Randomly select a part of data to train the model, holding the other part to test.\n",
    "    - **Repeated random sub-sampling validation**  \n",
    "    This method, also known as Monte Carlo cross-validation, randomly splits the dataset into training and validation data. For each such split, the model is fit to the training data, and predictive accuracy is assessed using the validation data. The results are then averaged over the splits.\n",
    "\n",
    "[1]:https://en.wikipedia.org/wiki/Cross-validation_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example\n",
    "In the [scikit-learn][1] documentation, an example to of cross-validation is presented in a simple SVM classification algorithm.  \n",
    "First, we provide a simple usage of svm class.\n",
    "[1]:http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     iris.data, iris.target, test_size=1./3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple usage\n",
    "The simplest way to implement cross-validation is to call [cross_val_score][2] like this\n",
    "\n",
    "```\n",
    "cross_val_score(estimator, X, y)\n",
    "```\n",
    "[2]:http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.96078431,  0.97916667])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, iris.data, iris.target)\n",
    "scores                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use other cross validation methods\n",
    "We can use other cross validation method. Simply import the cross validation method, and specify the parameter such as number of splits, test size. The object can be used as a parameter defining the cross validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97777778,  0.97777778,  1.        ,  0.95555556,  1.        ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = iris.data.shape[0]\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, iris.data, iris.target, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShuffleSplit(n_splits=5, random_state=0, test_size=0.3, train_size=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, ```cv``` is call a cross-validator. Cross-validator involves two methods:\n",
    "\n",
    "\n",
    "\n",
    "```get_n_splits([X, y, groups])```:\tReturns the number of splitting iterations in the cross-validator   \n",
    "```split(X[, y, groups])```:  Generate indices to split data into training and test set.\n",
    "\n",
    "Now let's look at what cv contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv 1\n",
      "train data: \n",
      "[ 60 116 144 119 108  69 135  56  80 123 133 106 146  50 147  85  30 101\n",
      "  94  64  89  91 125  48  13 111  95  20  15  52   3 149  98   6  68 109\n",
      "  96  12 102 120 104 128  46  11 110 124  41 148   1 113 139  42   4 129\n",
      "  17  38   5  53 143 105   0  34  28  55  75  35  23  74  31 118  57 131\n",
      "  65  32 138  14 122  19  29 130  49 136  99  82  79 115 145  72  77  25\n",
      "  81 140 142  39  58  88  70  87  36  21   9 103  67 117  47]\n",
      "test data: \n",
      "[114  62  33 107   7 100  40  86  76  71 134  51  73  54  63  37  78  90\n",
      "  45  16 121  66  24   8 126  22  44  97  93  26 137  84  27 127 132  59\n",
      "  18  83  61  92 112   2 141  43  10]\n",
      "cv 2\n",
      "train data: \n",
      "[ 80 107  90   0  36 112   5  57 102  55  34 128  33  21  73   7  45 129\n",
      " 103 146 120  94  50 134  99 126 114   9  39  97 101  29  81  20  46  51\n",
      "  53  23  27   2  28  37 111  10  84 137 127  43  87  69 144 140  35  76\n",
      "   3  82 145 116  88  44 147   1  93  38  11 115  54  40  18  41  79  24\n",
      "  56  71  13  31  85  70 132 125 123 100  32 104  83 117 118 138  25 110\n",
      "  16  75 109 121  86 139   4  96  14  61  67 149  95  19  72]\n",
      "test data: \n",
      "[ 92 141 130 119  48 143 122  63  26  64  42 108  91  77  22 148   6  65\n",
      "  47  68  60  15 124  58 142  12  59 105  89  78  52 131 113  98  30 136\n",
      "  66 133  49  62  74  17 106   8 135]\n",
      "cv 3\n",
      "train data: \n",
      "[111 125 101 143  23 117  50 146   2 110 118 131  17   6 127  67 124  15\n",
      "  56 115 112  71 145 100  38  80 109  44 144 130  35  97  59  48 134  70\n",
      "  65  98 138  55  43 132 103  30 114  34  18 141 139  49  52  74  26  45\n",
      " 126  39   4  11  53 149  79   8   0   5 133  61 135   7  83  99  22  68\n",
      "  82  20  28  86  14  42  32  25  36  92  75  64 142 120  81  58  13 140\n",
      "  72  87 123  93  91 136  51 116  24  94 106  16  63 128 105]\n",
      "test data: \n",
      "[ 85 137  77 108 122 104 121  12  31  96 113 102  60  66 119  62  76  69\n",
      "  46 129   1  10   3  95  21  41  57  47  78  19 107  90   9 147 148  40\n",
      "  29  27  89  37  33  84  54  88  73]\n",
      "cv 4\n",
      "train data: \n",
      "[  2  56   1 135  81  18 104 100  41  15 148  53  79   6  98 132  13  11\n",
      "  10 136  47  60  61 103 145  22 130  55  82 112 149  62 141 120  86  20\n",
      "  66  35  17  88   4  45  50  57  59  44  70  32  78 133 110  96  87  74\n",
      "  89  38  51 116  46  43   8  92 101  21 127 118  73  30 107 124   5   0\n",
      "  95  83  71 144 102 126 108  91  85  67   7  84  72  94 125 109  26  68\n",
      "  28 121   3 134  69  99  36  24  39 128 113 129  58 140 131]\n",
      "test data: \n",
      "[114  49 138  23   9 122 146  80  90 117 111  75 147 143  97  76 123 139\n",
      " 137  54  34 115  64  65  25 142 119  40  63  42  19 105  93  16 106  12\n",
      "  33  52  29  31  77  27  37  14  48]\n",
      "cv 5\n",
      "train data: \n",
      "[ 54 103   8  79  30  91 138 112  50  96 146  70  61  99  39  84 104 117\n",
      " 101  10   2   9  66  83 121  26  28  42  20  65 137 109 102  80  71 114\n",
      "  51 128  86  37  92  48 142 107 140 110  73  76  64  52 149 144  87  34\n",
      "  32 105  12  29 147 111  46  53   7 145  97  18  33 120  55  49 126  36\n",
      "  40 123   3  24  94  63 141  17   4  58  69  82 125  89  57  47  45  72\n",
      "  62  78  74  90 133 129 127 119  21  25 136  35  81  77 100]\n",
      "test data: \n",
      "[ 15 143  23 108 124  31 132  22 113  41  14   5  88  16 135 122   1 115\n",
      "  67  13 130 116  11 106 148  56  43  75  60 131 139  98  27   6  38  93\n",
      "   0  19  85  95  44  68 134  59 118]\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for train, test in cv.split(iris.data):\n",
    "    print(\"cv \"+str(i))\n",
    "    print(\"train data: \")\n",
    "    print(train)\n",
    "    print(\"test data: \")\n",
    "    print(test)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table summarize the available cross validation methods:\n",
    "\n",
    "|**Usage**| **Cross Validator** | **Explanation** |\n",
    "| :---: | :---: | :---: | :--- |\n",
    "|i.i.d. data| ```KFold``` | KFold divides all the samples in k groups of samples, called folds (if $k = n$, this is equivalent to the Leave One Out strategy), of equal sizes (if possible). The prediction function is learned using $k - 1$ folds, and the fold left out is used for test. | \n",
    "|i.i.d. data| ```RepeatedKFold``` | RepeatedKFold repeats K-Fold n times. It can be used when one requires to run KFold n times, producing different splits in each repetition. | \n",
    "|i.i.d. data| ```LeaveOneOut``` | Each learning set is created by taking all the samples except one, the test set being the sample left out. | \n",
    "|i.i.d. data| ```LeavePOut``` | LeavePOut creates all the possible training/test sets by removing p samples from the complete set. For n samples, this produces ${n \\choose p}$ train-test pairs.| \n",
    "|i.i.d. data| ```ShuffleSplit``` | Samples are first shuffled and then split into a pair of train and test sets. | \n",
    "|class label based| ```StratifiedKFold``` | Each set contains approximately the same percentage of samples of each target class as the complete set. | \n",
    "|class label based| ```StratifiedShuffleSplit``` | creates splits by preserving the same percentage for each target class as in the complete set. | \n",
    "| grouped data |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
